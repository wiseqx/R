{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Taught Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I : \n",
    "Load Task3C_labeled.csv, Task3C_unlabeled.csv and Task3C_test.csv data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "Your next step is to start H2O:\n",
      "    > h2o.init()\n",
      "\n",
      "For H2O package documentation, ask for help:\n",
      "    > ??h2o\n",
      "\n",
      "After starting H2O, you can use the Web UI at http://localhost:54321\n",
      "For more information visit http://docs.h2o.ai\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Attaching package: 'h2o'\n",
      "\n",
      "The following objects are masked from 'package:stats':\n",
      "\n",
      "    cor, sd, var\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    %*%, %in%, &&, ||, apply, as.factor, as.numeric, colnames,\n",
      "    colnames<-, ifelse, is.character, is.factor, is.numeric, log,\n",
      "    log10, log1p, log2, round, signif, trunc\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#importing libraries and closing the warnings\n",
    "options(warn=-1)   \n",
    "library(h2o)        \n",
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate error rate\n",
    "error.rate <- function(Y1, T1){\n",
    "  if (nrow(Y1)!=nrow(T1)){\n",
    "    stop('error.rate: size of true lables and predicted labels mismatch')\n",
    "  }\n",
    "  return (sum(T1!=Y1)/nrow(T1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "H2O is not running yet, starting it now...\n",
      "\n",
      "Note:  In case of errors look at the following log files:\n",
      "    C:\\Users\\Qixuan\\AppData\\Local\\Temp\\RtmpARikUE/h2o_Qixuan_started_from_r.out\n",
      "    C:\\Users\\Qixuan\\AppData\\Local\\Temp\\RtmpARikUE/h2o_Qixuan_started_from_r.err\n",
      "\n",
      "\n",
      "Starting H2O JVM and connecting: .. Connection successful!\n",
      "\n",
      "R is connected to the H2O cluster: \n",
      "    H2O cluster uptime:         4 seconds 339 milliseconds \n",
      "    H2O cluster timezone:       Australia/Sydney \n",
      "    H2O data parsing timezone:  UTC \n",
      "    H2O cluster version:        3.18.0.8 \n",
      "    H2O cluster version age:    23 days  \n",
      "    H2O cluster name:           H2O_started_from_R_Qixuan_dml018 \n",
      "    H2O cluster total nodes:    1 \n",
      "    H2O cluster total memory:   6.00 GB \n",
      "    H2O cluster total cores:    4 \n",
      "    H2O cluster allowed cores:  4 \n",
      "    H2O cluster healthy:        TRUE \n",
      "    H2O Connection ip:          localhost \n",
      "    H2O Connection port:        54321 \n",
      "    H2O Connection proxy:       NA \n",
      "    H2O Internal Security:      FALSE \n",
      "    H2O API Extensions:         Algos, AutoML, Core V3, Core V4 \n",
      "    R Version:                  R version 3.4.3 (2017-11-30) \n",
      "\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "#If there is a proxy: proxy.old <- Sys.getenv('http_proxy'); Sys.setenv('http_proxy'='');\n",
    "localH2O =  h2o.init(nthreads = -1, port = 54321, max_mem_size = '6G', startH2O = TRUE)\n",
    "\n",
    "# Use the \"absolute\" path to the datasets on machine\n",
    "labeled.frame <- h2o.importFile(path = 'C:/Users/Qixuan/Desktop/5201A2/assessments_datasets/Task3C_labeled.csv' ,sep=',') \n",
    "unlabeled.frame <- h2o.importFile(path = 'C:/Users/Qixuan/Desktop/5201A2/assessments_datasets/Task3C_unlabeled.csv' ,sep=',') \n",
    "test.frame <- h2o.importFile(path = 'C:/Users/Qixuan/Desktop/5201A2/assessments_datasets/Task3C_test.csv' ,sep=',') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove NA in unlabeled dataset\n",
    "unlabeled.frame<- na.omit(unlabeled.frame)\n",
    "\n",
    "#combining labeled dataframe and unlabeled dataframe\n",
    "train.frame <- h2o.rbind(labeled.frame, unlabeled.frame)\n",
    "\n",
    "#change labels to factor format\n",
    "labeled.frame[,1] <- as.factor(labeled.frame$label)\n",
    "test.frame[,1] <- as.factor(test.frame$label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build reconstruction and classification error matrix for training and test dataset\n",
    "reconstruction.train.error <- matrix(NA, nrow=25, ncol=1)\n",
    "classification.labeled.error <- matrix(NA, nrow=25, ncol=1)\n",
    "reconstruction.test.error <- matrix(NA, nrow=25, ncol=1)\n",
    "classification.test.error <- matrix(NA, nrow=25, ncol=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II & III & V: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build a function for building encoder models\n",
    "model_func <- function(x){\n",
    "  nn.model=h2o.deeplearning(      #call function \n",
    "  x = 1:ncol(train.frame),        # select all pixels + extra features\n",
    "  training_frame = train.frame,   # specify the frame (labeled+unlabeled)    \n",
    "  hidden = c(x),                  # number of layers and their units\n",
    "  epochs = 50,                    # maximum number of epoches  \n",
    "  activation = 'Tanh',            # activation function \n",
    "  autoencoder = TRUE,             # is it an autoencoder? Yes!\n",
    "  l2 = 0.1                        # specify the L2 regularisation weight to add stability\n",
    ")\n",
    "  return(nn.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training model with original data + extra feature\n",
    "model_func2 <- function(df){  \n",
    "  nn.model=h2o.deeplearning(       # build a NN classifier based on the labeled training data\n",
    "  x = 2:ncol(df),                  # select all pixels + extra features\n",
    "  y = 1,                           # specify training label\n",
    "  training_frame = df,             # specify the frame (imported file)    \n",
    "  hidden = c(100),                 # number of layers and their units\n",
    "  epochs = 50,                     # maximum number of epoches  \n",
    "  activation = 'Tanh',             # activation function \n",
    "  autoencoder = FALSE,             # is it an autoencoder? No!\n",
    "  l2 = 0.1                         # specify the L2 regularisation weight to add stability\n",
    ")\n",
    "  return(nn.model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n",
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "i=1\n",
    "for (k in seq(20, 500, 20)){ # for different neurons in the hidden layer seq(20,80,20)\n",
    "  \n",
    "  #### Q3.2 & Q3.3:\n",
    "  ## Train an autoencoder with only one hidden layer and change the number of its neurons to: 20, 40, 60, 80, .., 500\n",
    "  ## Calculate and record the reconstruction error\n",
    "    \n",
    "  model<-model_func(k)    #build a autoencoder model\n",
    "  mse<-h2o.anomaly(model,train.frame)    #calculate MSE for each images \n",
    "  reconstruction.train.error[i]<-mean(mse) #calculate the average of MSE \n",
    "\n",
    "  #### Q3.5\n",
    "  ## A. Add the output of the middle layer as extra features to the original feature set,\n",
    "  ## B. Train a 3-layer NN (similar to Step IV) using all features (original + extra). Then calculate and record the test error.\n",
    "\n",
    "  project<- h2o.deepfeatures(model, labeled.frame[,-1], layer=1)    # extract the middle layer as extra features\n",
    "  project<- as.h2o(project)                                         #format the features table\n",
    "  cancat.df<-h2o.cbind(labeled.frame, project)                      #combine original data and new features\n",
    "  labeled.predict <- h2o.predict(model_func2(cancat.df), test.frame)$predict     #predict labels\n",
    "  classification.test.error[i]<-error.rate(test.frame$label, labeled.predict)    #calculate errors\n",
    "  i<-i+1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.030183028</td></tr>\n",
       "\t<tr><td>0.014946623</td></tr>\n",
       "\t<tr><td>0.010282409</td></tr>\n",
       "\t<tr><td>0.008430945</td></tr>\n",
       "\t<tr><td>0.008840729</td></tr>\n",
       "\t<tr><td>0.007460532</td></tr>\n",
       "\t<tr><td>0.007786399</td></tr>\n",
       "\t<tr><td>0.008503481</td></tr>\n",
       "\t<tr><td>0.007588918</td></tr>\n",
       "\t<tr><td>0.007692004</td></tr>\n",
       "\t<tr><td>0.008485839</td></tr>\n",
       "\t<tr><td>0.009242178</td></tr>\n",
       "\t<tr><td>0.009380728</td></tr>\n",
       "\t<tr><td>0.008023988</td></tr>\n",
       "\t<tr><td>0.008186006</td></tr>\n",
       "\t<tr><td>0.008099607</td></tr>\n",
       "\t<tr><td>0.008161915</td></tr>\n",
       "\t<tr><td>0.008537450</td></tr>\n",
       "\t<tr><td>0.009439474</td></tr>\n",
       "\t<tr><td>0.008740141</td></tr>\n",
       "\t<tr><td>0.008396207</td></tr>\n",
       "\t<tr><td>0.008477287</td></tr>\n",
       "\t<tr><td>0.008027079</td></tr>\n",
       "\t<tr><td>0.009042759</td></tr>\n",
       "\t<tr><td>0.009276641</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.030183028\\\\\n",
       "\t 0.014946623\\\\\n",
       "\t 0.010282409\\\\\n",
       "\t 0.008430945\\\\\n",
       "\t 0.008840729\\\\\n",
       "\t 0.007460532\\\\\n",
       "\t 0.007786399\\\\\n",
       "\t 0.008503481\\\\\n",
       "\t 0.007588918\\\\\n",
       "\t 0.007692004\\\\\n",
       "\t 0.008485839\\\\\n",
       "\t 0.009242178\\\\\n",
       "\t 0.009380728\\\\\n",
       "\t 0.008023988\\\\\n",
       "\t 0.008186006\\\\\n",
       "\t 0.008099607\\\\\n",
       "\t 0.008161915\\\\\n",
       "\t 0.008537450\\\\\n",
       "\t 0.009439474\\\\\n",
       "\t 0.008740141\\\\\n",
       "\t 0.008396207\\\\\n",
       "\t 0.008477287\\\\\n",
       "\t 0.008027079\\\\\n",
       "\t 0.009042759\\\\\n",
       "\t 0.009276641\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.030183028 | \n",
       "| 0.014946623 | \n",
       "| 0.010282409 | \n",
       "| 0.008430945 | \n",
       "| 0.008840729 | \n",
       "| 0.007460532 | \n",
       "| 0.007786399 | \n",
       "| 0.008503481 | \n",
       "| 0.007588918 | \n",
       "| 0.007692004 | \n",
       "| 0.008485839 | \n",
       "| 0.009242178 | \n",
       "| 0.009380728 | \n",
       "| 0.008023988 | \n",
       "| 0.008186006 | \n",
       "| 0.008099607 | \n",
       "| 0.008161915 | \n",
       "| 0.008537450 | \n",
       "| 0.009439474 | \n",
       "| 0.008740141 | \n",
       "| 0.008396207 | \n",
       "| 0.008477287 | \n",
       "| 0.008027079 | \n",
       "| 0.009042759 | \n",
       "| 0.009276641 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      [,1]       \n",
       " [1,] 0.030183028\n",
       " [2,] 0.014946623\n",
       " [3,] 0.010282409\n",
       " [4,] 0.008430945\n",
       " [5,] 0.008840729\n",
       " [6,] 0.007460532\n",
       " [7,] 0.007786399\n",
       " [8,] 0.008503481\n",
       " [9,] 0.007588918\n",
       "[10,] 0.007692004\n",
       "[11,] 0.008485839\n",
       "[12,] 0.009242178\n",
       "[13,] 0.009380728\n",
       "[14,] 0.008023988\n",
       "[15,] 0.008186006\n",
       "[16,] 0.008099607\n",
       "[17,] 0.008161915\n",
       "[18,] 0.008537450\n",
       "[19,] 0.009439474\n",
       "[20,] 0.008740141\n",
       "[21,] 0.008396207\n",
       "[22,] 0.008477287\n",
       "[23,] 0.008027079\n",
       "[24,] 0.009042759\n",
       "[25,] 0.009276641"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show reconstrction errors\n",
    "reconstruction.train.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.539</td></tr>\n",
       "\t<tr><td>0.515</td></tr>\n",
       "\t<tr><td>0.603</td></tr>\n",
       "\t<tr><td>0.605</td></tr>\n",
       "\t<tr><td>0.584</td></tr>\n",
       "\t<tr><td>0.626</td></tr>\n",
       "\t<tr><td>0.545</td></tr>\n",
       "\t<tr><td>0.585</td></tr>\n",
       "\t<tr><td>0.565</td></tr>\n",
       "\t<tr><td>0.561</td></tr>\n",
       "\t<tr><td>0.364</td></tr>\n",
       "\t<tr><td>0.355</td></tr>\n",
       "\t<tr><td>0.593</td></tr>\n",
       "\t<tr><td>0.655</td></tr>\n",
       "\t<tr><td>0.581</td></tr>\n",
       "\t<tr><td>0.608</td></tr>\n",
       "\t<tr><td>0.629</td></tr>\n",
       "\t<tr><td>0.515</td></tr>\n",
       "\t<tr><td>0.575</td></tr>\n",
       "\t<tr><td>0.578</td></tr>\n",
       "\t<tr><td>0.582</td></tr>\n",
       "\t<tr><td>0.549</td></tr>\n",
       "\t<tr><td>0.615</td></tr>\n",
       "\t<tr><td>0.627</td></tr>\n",
       "\t<tr><td>0.604</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.539\\\\\n",
       "\t 0.515\\\\\n",
       "\t 0.603\\\\\n",
       "\t 0.605\\\\\n",
       "\t 0.584\\\\\n",
       "\t 0.626\\\\\n",
       "\t 0.545\\\\\n",
       "\t 0.585\\\\\n",
       "\t 0.565\\\\\n",
       "\t 0.561\\\\\n",
       "\t 0.364\\\\\n",
       "\t 0.355\\\\\n",
       "\t 0.593\\\\\n",
       "\t 0.655\\\\\n",
       "\t 0.581\\\\\n",
       "\t 0.608\\\\\n",
       "\t 0.629\\\\\n",
       "\t 0.515\\\\\n",
       "\t 0.575\\\\\n",
       "\t 0.578\\\\\n",
       "\t 0.582\\\\\n",
       "\t 0.549\\\\\n",
       "\t 0.615\\\\\n",
       "\t 0.627\\\\\n",
       "\t 0.604\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0.539 | \n",
       "| 0.515 | \n",
       "| 0.603 | \n",
       "| 0.605 | \n",
       "| 0.584 | \n",
       "| 0.626 | \n",
       "| 0.545 | \n",
       "| 0.585 | \n",
       "| 0.565 | \n",
       "| 0.561 | \n",
       "| 0.364 | \n",
       "| 0.355 | \n",
       "| 0.593 | \n",
       "| 0.655 | \n",
       "| 0.581 | \n",
       "| 0.608 | \n",
       "| 0.629 | \n",
       "| 0.515 | \n",
       "| 0.575 | \n",
       "| 0.578 | \n",
       "| 0.582 | \n",
       "| 0.549 | \n",
       "| 0.615 | \n",
       "| 0.627 | \n",
       "| 0.604 | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "      [,1] \n",
       " [1,] 0.539\n",
       " [2,] 0.515\n",
       " [3,] 0.603\n",
       " [4,] 0.605\n",
       " [5,] 0.584\n",
       " [6,] 0.626\n",
       " [7,] 0.545\n",
       " [8,] 0.585\n",
       " [9,] 0.565\n",
       "[10,] 0.561\n",
       "[11,] 0.364\n",
       "[12,] 0.355\n",
       "[13,] 0.593\n",
       "[14,] 0.655\n",
       "[15,] 0.581\n",
       "[16,] 0.608\n",
       "[17,] 0.629\n",
       "[18,] 0.515\n",
       "[19,] 0.575\n",
       "[20,] 0.578\n",
       "[21,] 0.582\n",
       "[22,] 0.549\n",
       "[23,] 0.615\n",
       "[24,] 0.627\n",
       "[25,] 0.604"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#show classification errors\n",
    "classification.test.error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV:\n",
    "Use the 3-layer NN or “h2o.deeplearning” function to build a model with 100 units in the hidden layer using\n",
    "all the original attributes from the training set. Then, calculate and record the test\n",
    "error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    }
   ],
   "source": [
    "# build a neural network classifier based on the labeled training data\n",
    "NN.model <- h2o.deeplearning(    \n",
    "  x = 2:ncol(labeled.frame),      # select all pixels + extra features\n",
    "  y = 1,                          # specify training label\n",
    "  training_frame = labeled.frame, # specify the frame (using labeled data required from Q1)    \n",
    "  hidden = c(100),                # number of layers and their units\n",
    "  epochs = 50,                    # maximum number of epoches  \n",
    "  activation = 'Tanh',            # activation function \n",
    "  autoencoder = FALSE,            # is it an autoencoder? No!\n",
    "  l2 = 0.1                        # specify the L2 regularisation weight to add stability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  |======================================================================| 100%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "0.55"
      ],
      "text/latex": [
       "0.55"
      ],
      "text/markdown": [
       "0.55"
      ],
      "text/plain": [
       "[1] 0.55"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#predict the label and calculate the error\n",
    "labeled.predict <- h2o.predict(NN.model, test.frame)$predict\n",
    "q4.error<-error.rate(test.frame$label, labeled.predict)\n",
    "q4.error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the needed plots.\n",
    "#set K\n",
    "K.data<-seq(20,500,20)\n",
    "G.data<-K.data+ncol(labeled.frame)\n",
    "#build a data frame for error\n",
    "reconst.error<-data.frame(cbind(rep(K.data, 1, each=1),reconstruction.train.error))\n",
    "misclust.error<-data.frame(cbind(rep(G.data, 1, each=1),classification.test.error))\n",
    "\n",
    "#give it a column name\n",
    "names(reconst.error)<-c('Number_of_neurons','Error_rate')\n",
    "names(misclust.error)<-c('Number_of_features','Error_rate')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAM1BMVEUAAABNTU1oaGh8fHyM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\nQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting \n",
    "ggplot(data=reconst.error, aes(x=Number_of_neurons, y=Error_rate)) +\n",
    "  geom_line() +\n",
    "  labs(title='Reconstruction error rate VS Number of units in hidden layers') +  \n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### explain findings based on the plot:\n",
    "With the number of units in the hidden layer increasing, the reconstruction error is decreasing. It has a dramatic decrease until the number of units up to 100. After that, the average error rate is around 0.9% as the number of units increasing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI\n",
    "Plot the error rates for the 3-layer neural networks from Step IV and V while the\n",
    "x-axis is the number of features and y-axis is the classification error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAP1BMVEUAAAABAQEHBwcWFhY2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\nxCCIRIhBEIkQgyASIQb5f/tN7MW5NuVuAAAAAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plotting classfication errors\n",
    "ggplot(data=misclust.error, aes(x=Number_of_features, y=Error_rate),label=\"Q4\") +\n",
    "  geom_line() +\n",
    "  geom_point(aes(x=ncol(train.frame)-1, y=q4.error), size=3) +\n",
    "  geom_text(aes(x=ncol(train.frame)-1, y=q4.error-0.01, label=\"Q4\"))+\n",
    "  labs(title='Classification error VS Number of features') +  \n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII:\n",
    "Report the optimum number(s) of units in the middle layer of the autoencoder in\n",
    "terms of the reconstruction and misclassification errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the misclassfication error hebavior is undisireable (It may caused by small training data set or model overfitting). We can just infer the optimum units from the reconstruction error plot. I think the optimal units should be 100. Because the error has a dramatic decrease until the number of units up to 100. And then, the average error tends to be gentle. Also, the performance difference does not have any changes when the hidden layers increasing start from 100. So we could eliminate unnecessary and redundant nodes and take 100 as our optimum units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIII:\n",
    "Comparing the plot from Step III and VI, do you observe any relation between\n",
    "the reconstruction error and misclassification error? Explain your finding in your Notebook\n",
    "file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the plots above, there is less relation between the reconstruction error and misclassfication error because there is too small training data set as well as too large test set to make the misclassfication errors behaviour abnormal. We can see the errors are all around 60%, and the error around 30% is a occasional event. But in fact, if we have optimal enough training set, we might see that with the increasing of number of features or with the increasing number of neurons, the errors would be decreasing. However, there should be a point where can keep the error around (in our 3 layer case, it is 100). Also, with the increasing number of features, the error would be increase after a specific number of features because too many parameters would make the model overfitting.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
